<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Vacancies</title>

<script src="site_libs/header-attrs-2.16/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Neuroling</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Projects.html">Projects</a>
</li>
<li>
  <a href="People.html">People</a>
</li>
<li>
  <a href="Vacancies.html">Vacancies</a>
</li>
<li>
  <a href="Publications.html">Publications</a>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
<li>
  <a href="Documentation.html">Documentation</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Vacancies</h1>

</div>

<div id="TOC">
<ul>
<li><a
href="#master-thesis-machine-learning-eeg-neurofeedback-and-degraded-speech-perception"
id="toc-master-thesis-machine-learning-eeg-neurofeedback-and-degraded-speech-perception"><strong>Master
Thesis:</strong> Machine Learning, EEG Neurofeedback and degraded speech
perception</a></li>
<li><a
href="#master-thesis-audio-and-video-driven-features-in-audiovisual-speech-perception"
id="toc-master-thesis-audio-and-video-driven-features-in-audiovisual-speech-perception"><strong>Master
Thesis:</strong> Audio and video-driven features in audiovisual speech
perception</a></li>
<li><a
href="#master-thesis-investigating-motor-contributions-to-speech-perception-using-transcranial-electrical-stimulation"
id="toc-master-thesis-investigating-motor-contributions-to-speech-perception-using-transcranial-electrical-stimulation"><strong>Master
Thesis:</strong> Investigating motor contributions to speech perception
using transcranial electrical stimulation</a></li>
<li><a
href="#master-thesis-behaviouralphysiological-responses-to-natively-accented-infant-cries."
id="toc-master-thesis-behaviouralphysiological-responses-to-natively-accented-infant-cries."><strong>Master
Thesis:</strong> Behavioural/Physiological responses to natively
accented infant-cries.</a></li>
</ul>
</div>

<!-- \_\_\_\_\_\_\_\_\_\_\_ -->
<!-- ### **Post-Doctoral Position**: Neural Dynamics of Sentence Processing -->
<!-- The *neurolinguisitics* team at the *University of Zurich* is recruiting a post-doctoral researcher with expertise in M/EEG and an interest in the neural basis of speech and language to work on a four-year cross-linguistic multidisciplinary project examining multiple aspects of naturalistic speech processing and reading. The project involves close collaboration between neurolinguists ([Alexis Hervais-Adelman](https://neuroling.github.io/)), computational linguists ([Lena Jäger](https://www.cl.uzh.ch/en/digital-linguistics/people/group-leader/jaeger.html)) and linguists ([Marianne Hundt](https://www.linguistik.uzh.ch/en/about/mitglieder/hundt.html), [Fernando Zúñiga](https://www.isw.unibe.ch/ueber_uns/personen/prof_dr_ziga_fernando/index_ger.html)).  -->
<!-- The successful candidate will be responsible for the implementation of a series of investigations that examine the neural signatures of various combinatorial processes and combine computational linguistic approaches to semantic embedding spaces with temporally resolved brain recordings in order to elucidate the neural signatures of combinatorial meaning-building operations using MEG.   -->
<!-- **Person Specification:**  -->
<!-- You have a strong methodological background M/EEG, an interest in neurolinguistics and a passion for multidisciplinary research. You are able to communicate and collaborate productively with scholars of different disciplines. You are solution-oriented, well-organised and enjoy taking the lead. You share your expertise with other members of the team and actively contribute to project development. You have a desire to learn new techniques and determination to master complex analyses.   -->
<!-- **Requirements:**  -->
<!-- -   PhD in a relevant discipline (e.g. Cognitive neuroscience of language or a related field)  -->
<!-- -   Significant expertise in M/EEG, including data acquisition, preprocessing and advanced analysis   -->
<!-- -   Programming skills required for data analysis and experimental design (e.g. Psychtoolbox, PsychoPy, MNE-python, scikit-learn)  -->
<!-- <!-- -->
<!-- -   Excellent written and spoken English  -->
<!-- -   Experience supervising students (MSc./Ph.D.) and research assistants  -->
<!-- -    A proven record of publication of M/EEG experiments in peer-reviewed journals appropriate for the career stage  -->
<!-- Desirable  -->
<!-- -   Flexibility to travel for off-site data acquisition  -->
<!-- <!-- -->
<!-- -   Analysis of time-resolved imaging data using temporal response function   -->
<!-- -   Familiarity with multivariate analysis methods including decoding/encoding approaches  -->
<!-- **The Team**  -->
<!-- The Neurolinguistics group in the Department of Psychology at the University of Zurich investigates the neural basis of language using multimethodological approaches including M/EEG, fMRI and brain stimulation. In addition to affiliation in the Department of Psychology, the successful candidate will benefit from an inspiring multidisciplinary research environment thanks to close contact with the [NCCR Evolving Language](https://evolvinglanguage.ch/), the [Zurich Centre for Linguistics](https://www.linguistik.uzh.ch/de.html) and the [Zurich Centre for Neuroscience](https://www.neuroscience.uzh.ch/en.html).   -->
<!-- We offer an inspiring research environment in an enthusiastic team, and the possibility of developing your profile within the scope of the project at one of Europe's leading (LERU) universities in one of the top ten most livable cities world-wide.  -->
<!-- **Desired start date**: as soon as practicable, flexible for the appropriate candidate.   -->
<!-- For further details or informal inquiries, please contact: Prof. Dr. Alexis Hervais-Adelman, [alexis.hervais-adelman\@psychologie.uzh.ch](mailto:alexis.hervais-adelman@psychologie.uzh.ch)  -->
<!-- Applications, with the reference "DNL02",  including your CV, list of publications (if applicable), motivation letter, names of two referees as a single PDF file should be sent to [Sarah.Krause\@uzh.ch](mailto:Sarah.Krause@uzh.ch). Applications will be considered until the vacancy is filled.  -->
<!--   -->
<!-- \_\_\_\_\_\_\_\_\_\_\_ -->
<div
id="master-thesis-machine-learning-eeg-neurofeedback-and-degraded-speech-perception"
class="section level3">
<h3><strong>Master Thesis:</strong> Machine Learning, EEG Neurofeedback
and degraded speech perception</h3>
<p>Reduced speech comprehension due to hearing impairments which can
have dramatic consequences for quality of life.</p>
<p>Our project aims at gaining fundamental knowledge on the
neurocognitive basis of our ability to comprehend degraded speech in
acoustically challenging situations. We will use
<em>electroencephalography</em> (EEG) and <em>machine learning
decoding</em> to investigate patterns of brain activity associated with
better speech in noise comprehension.</p>
<p>The ultimate goal of this project is to define better targets for
future neurofeedback.</p>
<p> - We offer hands-on experience collecting high-quality
electrophysiological data and applying advanced signal processing and
analysis techniques.    </p>
<p> - Number of theses on this project: 2-3</p>
<p> - Starting date negotiable</p>
<p>For more details, contact Dr. Gorka Fraga-Gonzalez, <a
href="mailto:gorka.fragagonzalez@uzh.ch"
class="email">gorka.fragagonzalez@uzh.ch</a></p>
<p>  ___________</p>
</div>
<div
id="master-thesis-audio-and-video-driven-features-in-audiovisual-speech-perception"
class="section level3">
<h3><strong>Master Thesis:</strong> Audio and video-driven features in
audiovisual speech perception</h3>
<p>The visual component of speech plays an important part in real-world
communication, as evidenced by the literature, and by mask-wearing
during the Covid19 pandemic. This audio-visual comprehension gain plays
a yet greater role for those living with hearing impairment – a majority
of the ageing population – so understanding the mechanisms which
underpin audio-visual integration is important for the development of
advanced hearing aids and for the hearing impaired. Despite a concerted
effort to this end over the past decades, several aspects of these
processes remain unclear – not least with respect to the role of
temporal and categorical cues carried by the visual component of speech,
and to the putative tuning of neural circuitry due to co-evolution of
language production and perception. This project aims to disentangle
these effects through a set of behavioural experiments on degraded
audio-visual speech comprehension carried out online and in the lab.
Findings will inform further studies with brain-imaging and contribute
to the development of solutions for individuals who suffer from hearing
impairment. </p>
<p>For more details, contact Enrico Varano, <a
href="mailto:enrico.varano@psychologie.uzh.ch"
class="email">enrico.varano@psychologie.uzh.ch</a></p>
<p>  ___________</p>
</div>
<div
id="master-thesis-investigating-motor-contributions-to-speech-perception-using-transcranial-electrical-stimulation"
class="section level3">
<h3><strong>Master Thesis:</strong> Investigating motor contributions to
speech perception using transcranial electrical stimulation</h3>
<p>Humans excel at the difficult task of parsing degraded speech. This
skill, which is apparent when communicating in noisy environments, in
the presence of unattended speakers, or in those wearing hearing
prostheses, is underpinned by a hierarchy of complex, distributed neural
processes. Perhaps surprisingly, evidence suggests neural circuitry
involved in speech production and planning thereof plays an important
part in speech perception as well. Despite a concerted effort to confirm
and describe the contribution of processes in the motor cortex to speech
perception, more work is required to elucidate the matter. This project
aims to observe such motor contributions to speech perception by
employing a transcranial electrical stimulation paradigm. Findings will
contribute to the development of solutions for individuals who suffer
from hearing impairment. </p>
<p>For more details, contact Enrico Varano, <a
href="mailto:enrico.varano@psychologie.uzh.ch"
class="email">enrico.varano@psychologie.uzh.ch</a></p>
<p>  ___________</p>
</div>
<div
id="master-thesis-behaviouralphysiological-responses-to-natively-accented-infant-cries."
class="section level3">
<h3><strong>Master Thesis:</strong> Behavioural/Physiological responses
to natively accented infant-cries.</h3>
<p>New-born infants are born without any ability to care for themselves
and thus require constant caregiver attention for their fundamental
needs to be met. Neonates, however, lack the ability to communicate
through speech and rely on crying to elicit caregiver attention, with
effective crying being sufficiently salient to capture attention, yet
not so aversive as to deter caregiver attention.New-born infants have
been shown to produce spontaneous cries that are natively accented, and
this project aims to investigate whether infant cry accent aids infant
survival by mediating the aversiveness of a cry for the caregiver.This
project offers potential to develop experience working with large data
sets acquired through online studies; the collection and analysis of
eye-tracking data; and working with/analysis of auditory stimuli in
psychoacoustics research.</p>
<p>Number of theses: 1-2</p>
<p>For more details, contact Huw Swanborough – <a
href="mailto:huw.swanborough@uzh.ch"
class="email">huw.swanborough@uzh.ch</a></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
